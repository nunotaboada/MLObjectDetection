

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>train &mdash; Object Detection  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Object Detection
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reports.html">Reports</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Object Detection</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Module code</a></li>
      <li class="breadcrumb-item active">train</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for train</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>

<span class="c1"># Define the base directory for storing model outputs, such as checkpoints and logs</span>
<span class="n">project_dir</span> <span class="o">=</span> <span class="s2">&quot;./models&quot;</span>
<span class="c1"># Set a unique name for this training experiment to organize output files</span>
<span class="n">experiment_name</span> <span class="o">=</span> <span class="s2">&quot;yolo_object_lane&quot;</span>
<span class="c1"># Create the project directory if it does not already exist, ensuring a safe destination for outputs</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">project_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Initialize the YOLO model using pre-trained weights from &#39;yolo11n.pt&#39;</span>
<span class="c1"># The &#39;yolo11n.pt&#39; is a lightweight YOLOv11 nano model, optimized for fast inference and suitable for object detection tasks</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">&quot;yolo11n.pt&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="main">
<a class="viewcode-back" href="../train.html#train.main">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train and validate a YOLO model for object detection with customizable parameters.</span>

<span class="sd">    This function configures a command-line argument parser to allow flexible specification of training parameters,</span>
<span class="sd">    trains the YOLO model using the Ultralytics library with a detailed set of hyperparameters, and validates the</span>
<span class="sd">    trained model on a specified dataset to evaluate performance metrics such as mAP. The training process includes</span>
<span class="sd">    data augmentation, checkpoint saving, and regularization to optimize model performance.</span>

<span class="sd">    Args:</span>
<span class="sd">        None: Arguments are parsed from the command line using argparse.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None: Outputs are saved to the project directory, and validation results are printed to the console.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Initialize an argument parser to capture command-line inputs for flexible training configuration</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Train a YOLO model for object detection with customizable parameters&quot;</span><span class="p">)</span>
    <span class="c1"># Specify the path to the dataset YAML file, which defines paths to training/validation data and class names</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--data&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;./dataset/data.yaml&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the dataset YAML file specifying train, validation, and class details&quot;</span><span class="p">)</span>
    <span class="c1"># Define the total number of training epochs to balance model convergence and potential overfitting</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--epochs&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Total number of training epochs to optimize the model&quot;</span><span class="p">)</span>
    <span class="c1"># Set the input image size for resizing images during training, ensuring consistency across inputs</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--imgsz&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">640</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Image size in pixels (square, e.g., 640x640) for resizing input images&quot;</span><span class="p">)</span>
    <span class="c1"># Specify the batch size for training, balancing memory usage and gradient stability</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--batch&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of images per batch during training&quot;</span><span class="p">)</span>
    <span class="c1"># Parse the provided command-line arguments into a namespace object</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="c1"># Train the YOLO model with a comprehensive set of hyperparameters to optimize performance</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
        <span class="c1"># Path to the dataset YAML file, which includes paths to train/validation images and class definitions</span>
        <span class="n">data</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
        <span class="c1"># Number of epochs to train the model, controlling the duration of training</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span>
        <span class="c1"># Resize all input images to this square dimension (e.g., 640x640 pixels) for consistent processing</span>
        <span class="n">imgsz</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span>
        <span class="c1"># Apply hue augmentation within a small range to simulate slight color variations in images</span>
        <span class="n">hsv_h</span><span class="o">=</span><span class="mf">0.015</span><span class="p">,</span>
        <span class="c1"># Adjust saturation to enhance robustness to changes in lighting and color intensity</span>
        <span class="n">hsv_s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="c1"># Modify brightness (value) to account for varying illumination conditions in real-world scenarios</span>
        <span class="n">hsv_v</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="c1"># Apply random translation (shifting) to images by up to 10% to improve spatial robustness</span>
        <span class="n">translate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="c1"># Randomly scale images by up to 20% to simulate objects at varying distances from the camera</span>
        <span class="n">scale</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="c1"># Flip images horizontally with a 50% probability to augment dataset symmetry and robustness</span>
        <span class="n">fliplr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="c1"># Apply mosaic augmentation (combining multiple images into one) with 50% probability to increase data diversity</span>
        <span class="n">mosaic</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="c1"># Use random erasing with 20% probability to simulate occlusions, improving robustness to partial object visibility</span>
        <span class="n">erasing</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="c1"># Disable auto-augmentation to rely solely on the specified augmentation parameters</span>
        <span class="n">auto_augment</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Set the batch size for training, controlling the number of images processed per iteration</span>
        <span class="n">batch</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span>
        <span class="c1"># Enable Automatic Mixed Precision (AMP) to reduce memory usage and speed up training on compatible hardware</span>
        <span class="n">amp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="c1"># Specify CPU as the training device (can be changed to GPU, e.g., &#39;cuda&#39;, if available for faster training)</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="c1"># Set the number of worker threads for data loading to optimize the data pipeline and reduce bottlenecks</span>
        <span class="n">workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="c1"># Define the directory where training outputs (checkpoints, logs, etc.) will be saved</span>
        <span class="n">project</span><span class="o">=</span><span class="n">project_dir</span><span class="p">,</span>
        <span class="c1"># Specify the experiment name to organize output files within the project directory</span>
        <span class="n">name</span><span class="o">=</span><span class="n">experiment_name</span><span class="p">,</span>
        <span class="c1"># Allow overwriting of existing experiment directory to avoid conflicts during repeated runs</span>
        <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="c1"># Set to 0 to train all model layers, ensuring maximum flexibility and no frozen weights</span>
        <span class="n">freeze</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="c1"># Set the initial learning rate for the optimizer to control the step size in gradient descent</span>
        <span class="n">lr0</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="c1"># Disable early stopping by setting patience to 0, ensuring all specified epochs are completed</span>
        <span class="n">patience</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="c1"># Apply weight decay for regularization to prevent overfitting by penalizing large weights</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">,</span>
        <span class="c1"># Save model checkpoints every 20 epochs to track progress and enable recovery</span>
        <span class="n">save_period</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="c1"># Enable saving of model checkpoints during training for later use or evaluation</span>
        <span class="n">save</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Perform validation on the trained model to evaluate its performance on the validation dataset</span>
    <span class="n">results_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">val</span><span class="p">(</span>
        <span class="c1"># Use the same dataset YAML file as in training to ensure consistency in data configuration</span>
        <span class="n">data</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
        <span class="c1"># Maintain the same image size as training for consistent evaluation</span>
        <span class="n">imgsz</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span>
        <span class="c1"># Use a larger batch size for validation to speed up the evaluation process</span>
        <span class="n">batch</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
        <span class="c1"># Use CPU for validation (can be changed to GPU, e.g., &#39;cuda&#39;, if available)</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="c1"># Generate visualization plots, such as confusion matrices and precision-recall curves, for performance analysis</span>
        <span class="n">plots</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Display key validation metrics to summarize model performance</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Results:&quot;</span><span class="p">)</span>
    <span class="c1"># Print mean Average Precision (mAP) at IoU=0.5, indicating detection performance at a moderate overlap threshold</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mAP@0.5: </span><span class="si">{</span><span class="n">results_val</span><span class="o">.</span><span class="n">box</span><span class="o">.</span><span class="n">map50</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Print mAP averaged over IoU thresholds from 0.5 to 0.95, providing a comprehensive performance metric</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mAP@0.5:0.95: </span><span class="si">{</span><span class="n">results_val</span><span class="o">.</span><span class="n">box</span><span class="o">.</span><span class="n">map</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Iterate through class names and display per-class mAP@0.5:0.95 for detailed performance breakdown</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">results_val</span><span class="o">.</span><span class="n">names</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mAP@0.5:0.95 for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">results_val</span><span class="o">.</span><span class="n">box</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Entry point for executing the YOLO model training and validation pipeline.</span>

<span class="sd">    This block serves as the main entry point for the script, invoking the main function</span>
<span class="sd">    to configure, train, and validate the YOLO model for object detection tasks.</span>

<span class="sd">    Args:</span>
<span class="sd">        None</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, SEAME Porto-Portugal Team07.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>